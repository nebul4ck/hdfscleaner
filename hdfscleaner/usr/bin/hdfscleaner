#!/usr/bin/python
# -*- encoding: utf-8 -*-

"""
.. module:: main
   :platform: GNU/Linux
   :synopsis: Clean Hadoop old files.
.. moduleauthor::
   :Nickname: nebul4ck
   :mail: a.gonzalezmesas@gmail.com
   :Web :	https://github.com/nebul4ck/hdfscleaner
"""
import sys
import pyconcrete

from hdfscleaner.lib.AppLoader import AppLoader
from hdfscleaner.lib.logger import logger as l

""" Global vars """
num_params = len(sys.argv)

def use():
	""" HDFSCLEANER

	usage: hdfscleaner <APP>
	NAME
		hdfscleaner - Cleans <APP> old files from Hadoop Cluster.
	SYNOPSIS
		hdfscleaner <APP>
	DESCRIPTION
		Hdfscleaner is a tool that deletes applications (APP) all old files from Hadoop Cluster.
		A example:
			When Druid pushes data segments into Hadoop cluster (Handoff) these datas persist along
			the time and never drop its. Druid has rules that controls it but only in local historical
			node. hdfscleaner drops data segments from hadoop cluster when a druid rule is matchs, so
			Druid local data and remote hadoop data will be droped.

		Another example:
			Elasticsearch-curator pushes elasticsearch snapshots or index in Hadoop cluster, with hdfs
			cleaner we can delete these.
	APP
		Druid 	- Drops old data segments.
		Elasticsearch 	- Deletes old elasticsearch-snapshots and elasticsearch-index from Hadoop cluster.

	EXAMPLES
		$ hdfscleaner druid
	"""
	exit(0)


""" Launch deletede Druid old files """
def launcher(application):

	appLoader = AppLoader('hdfscleaner.lib')

	loadClass = appLoader.get_instance(application)

	launch_cleaner = loadClass.launcher()

	return launch_cleaner

""" Runs hdfscleaner """
if num_params is not 2 :
	help(use)
else:
	application = sys.argv[1]
	run_command = launcher(application)
	l.info(run_command)
